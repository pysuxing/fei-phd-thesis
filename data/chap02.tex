\chapter{相关研究工作}
本章介绍高性能互连网络设计的相关背景知识。
首先介绍了物理器件对新型高性能互连网络的影响，
之后介绍了典型的高性能互连网络拓扑结构和路由算法以及拥塞控制机制。

\section{物理器件对高性能互连网络的影响}
传统的高性能互连网络拓扑大致分为两类
，一类是以$k\textrm{-}ary$ $n\textrm{-}fly$蝶形网络为代表的间接网络，
如图\ref{butterfly}所示。
$k\textrm{-}ary$ $n\textrm{-}fly$结构中，节点度数为$2k$，采用单向链路，
网络直径为$n-1$，网络规模为$k^n$。
一类是以$k\textrm{-}ary$ $n\textrm{-}cube$网络为代表的直接网络，
如图\ref{torus} 所示。
$k\textrm{-}ary$ $n\textrm{-}cube$结构中，节点度数为$2n$，采用双向链路，
网络直径为$n \lfloor k/2 \rfloor$，网络规模为$k^n$。
%% FIXME $n(\lfloor\frac{k}{2}\rfloor)$
当$k=2$时，$k\textrm{-}ary$ $n\textrm{-}cube$结构就是经典的超立方体（Hypercube）结构，
是第一代高性能计算机的主要拓扑结构。
如Intel iPSC/2\upcite{ipsc2}、 NCUBE/10\upcite{ncube}、
SGI Origin 2000\upcite{sgi2000} 等系统均采用了Hypercube结构，
因为其具有正则性、对称性、强容错性以及可嵌入性等特点。
当$k=n$时，$k\textrm{-}ary$ $n\textrm{-}fly$结构和$k\textrm{-}ary$ $n\textrm{-}cube$结构规模一样，
节点度数一样，但是$k\textrm{-}ary$ $n\textrm{-}cube$结构的网络直径大约是
$k\textrm{-}ary$ $n\textrm{-}fly$结构的$k/2$倍。
$k\textrm{-}ary$ $n\textrm{-}fly$结构拥有更小的网络直径，
但是，路径唯一性及负载不均衡是限制其扩展的主要原因。

%% FIXME annotate these two figures with concreate n/k values?
%% FIXME also more explanation needed in the text?
\begin{figure}[htp]
  \centering
   \includegraphics[width=.48\textwidth,height=.38\textwidth]{Visio-butterfly.eps}
    \caption{$k\textrm{-}ary$ $n\textrm{-}fly$结构}
    \label{butterfly}
\end{figure}

\begin{figure}[htp]
  \centering
   \includegraphics[width=.44\textwidth,height=.38\textwidth]{Visio-torus.eps}
      \caption{$k\textrm{-}ary$ $n\textrm{-}cube$结构}
      \label{torus}
\end{figure}

%% FIXME 10Gb/s or 10GB/s
上世纪90年代，路由芯片引脚带宽上限约为10Gb/s，
%% FIXME 端口数受限是因为引脚带宽低？
路由芯片也因此端口数受限制。
传统的高性能互连网络只能采用低节点度的拓扑结构。
随着半导体和集成电路的发展，路由芯片的引脚带宽增加，芯片端口数也随之增加。
如Cray公司推出的端口数为64的YARC路由芯片
\upcite{yarc}\upcite{blackwindow}、2010年HOTI
会议上提出的48端口Gemini芯片\upcite{cascade}、
2015年HOTI会议上提出48端口的Intel Omni-Path芯片\upcite{omni}以及
Mellanox公司最新推出的Quantum 200G HDR InfiniBand Switch\upcite{quantum}。
相比拥有较少宽带宽端口的路由芯片，
采用拥有更多窄带宽端口的路由芯片搭建高性能互连网络可以降低网络的延迟和成本开销。
根据Kim的推导，低负载下报文的网络延迟为$T=T_h+T_s=Ht_r+L/b$，
其中$H$是报文的跳步数，$t_r$是每一跳经过路由器的延迟，$L$是报文的长度，
$b$则是链路的带宽。
在规模为$N$的网络中，若使用端口数为$k$的路由芯片（$k$个输入通道加$k$个输出通道），
其跳步数最少为$2log_{k}N$。
若芯片的总带宽为$B$，则$b=B/2k$。
那么网络延迟为$T=2t_{r}log_{k}N+2kL/B$，对$k$求导，
当$dT/dk=0$时可得到网络延迟$T$取最小值时端口数$k$满足$klog^2k=Bt_rlogN/L$。
随着网络规模$N$增加，路由芯片的最佳端口数$k$也随之增加。
%% 不要一句话不停重复地说……
%% 因此，基于高阶路由器设计的高性能互连网络成为高性能互连网络设计的主流趋势。
随着路由器端口数的增加，基于高阶路由器的网络拓扑结构相继被提出，
如Flattened Butterlfy \upcite{Flattenedbutterfly}、Dragonfly \upcite{dragonfly}、
HyperX \upcite{hyperx}等。
相比传统的高性能互连网络拓扑结构，
基于高阶路由器设计的网络拓扑结构不仅可以在降低网络直径的前提下支持更大的网络规模，
还可以减少路由器的数量。
Kim曾预测，未来几年内将会出现数百个端口的路由芯片，
2010年单芯片的总带宽会突破20Tb/s\upcite{yarc}\upcite{blackwindow}。
但是，实际上目前最新的商用芯片总带宽只能达到16Tbps\upcite{quantum}。
总体上，虽然路由芯片取得了长足的发展，
但采用目前的高性能互连网络仍远不足以构建E级计算系统，
如何利用当前商用高阶路由芯片搭建E级计算系统已经成为高性能互连网络研究的关键问题。

光纤技术的发展使得高性能互连网络在实际部署中引入光缆代替部分电缆。
低直径的新型高性能互连网络拓扑结构相比传统的高性能互连网络拓扑结构，
拥有更多的全局链路以降低网络直径。
对全局链路采用光纤部署，不仅在性能上有优势，而且在能耗上独立于缆线的物理长度。
研究表明，10米以内的链路，采用光纤的成本相比电缆的成本要高，
而10米以上的链路，
则采用电缆的成本要比光纤的高\upcite{dragonfly}。
因此，为了降低系统成本，
Dragonfly结构在保证网络直径低的前提下，
每个超级节点只引出一条全局链路连接相邻超级节点\upcite{dragonfly}。
但是，E级计算系统的应用负载复杂多样，
除了对网络结构的局部性有要求外，全局通信将更加频繁，
若只保证超级节点间
只有一条全局链路，已不能满足应用负载的需求。
从边缘可插拔光纤收发器到主板集成光模块的转变\upcite{BOA}，
多芯光纤（Multicore Fiber）\upcite{MCF}的出现
给高性能互连网络设计带来了新的契机，
这给提升实际部署中机柜间通信带宽提供了更多空间。
多芯光纤，如图\ref{mcf}所示，实际上就是一条光缆里有多个纤芯的光缆，
可以通过分线器分成多个单芯光纤。
一条多芯光纤相比同等纤芯数的一捆单芯光纤，
不仅成本上更加经济，而且维护上更加容易。
因此，如何在高性能互连网络中更好地利用多芯光纤，
有效提升全局通信带宽并保证可扩展性，提高可维护性是构建
E级计算系统的关键问题。

\begin{figure}[htp]
  \centering
    \includegraphics[width=.48\textwidth,height=.38\textwidth]{Visio-SCF.eps}
    \caption{单芯光纤}
    \label{scf}
\end{figure}

\begin{figure}[htp]
  \centering
    \includegraphics[width=.48\textwidth,height=.38\textwidth]{Visio-MCF.eps}
      \caption{多芯光纤}
       \label{mcf}
\end{figure}

\section{高性能互连网络拓扑结构}

\subsection{Fat tree}
Fat tree\upcite{fattree}是最早的大规模低直径高性能互连网络拓扑结构。
国防科技大学自主研制的天河一号和天河二号高性能计算机均采用Fat tree结构。
Fat tree是一个灵活性和扩展性都较优的拓扑结构，
最大的特点在于随着网络规模的增加，二分带宽也随之等规模增加。
其可以看成是两个$k\textrm{-}ary$ $n\textrm{-}fly$结构合并而成，
如图\ref{fattree}所示由两个图\ref{butterfly}合并而成，采用双向链路。
%% FIXME use concreate n/k
两个蝶形结构分别起到负载均衡和控制输入输出的作用，
因此，Fat tree继承了蝶形结构网络直径低的优点，
并且可以有效避免蝶形网络路径唯一和负载不均衡等缺点。
Fat tree的节点度数为$2k$，网络直径为$2(n-1)$，
网络规模$2k^n$，且需要$(2n-1)k^{n-1}$个路由器。
%% FIXME 如何用n/k定义胖树？
\begin{figure}[htp]
  \centering
    \includegraphics[width=.48\textwidth,height=.38\textwidth]{Visio-fattree.eps}
    \caption{Fat tree结构}
     \label{fattree}
\end{figure}

\subsection{Flattened Butterlfy}

Flattened Butterfly\upcite{Flattenedbutterfly}是2007年Kim等人
在ISCA会议上提出的一个性价比较高的高阶互连网络。
Flattened Butterfly结构充分利用高阶路由器提供的丰富链路特性，
使得$k\textrm{-}ary$ $n\textrm{-}cube$结构中每一维上的路由节点都是全互连，
其节点度为$(n+1)(k-1)+1$，网络直径为$n$，网络规模为$k^{n+1}$。
%% FIXME 如何用n/k定义FB
Flattened Butterfly利用高阶路由器，
不仅有效解决了$k\textrm{-}ary$ $n\textrm{-}cube$结构网络直径长的问题
而且通过合并$k\textrm{-}ary$ $n\textrm{-}fly$结构中的路由器，有效降低了路由器的数量。
如图\ref{flattenedbutterfly}所示，图左是$k\textrm{-}ary$ $n\textrm{-}fly$ 结构，
图右是合并了蝶形网络中每一层的路由器的Flattened Butterfly。
与Fat tree相比，当搭建同样规模和同样直径的网络时，
Flattened Butterfly可以节省近一半的链路。

\begin{figure}[htp]
  \centering
    \includegraphics[width=.56\textwidth,height=.35\textwidth]{Visio-flattenedbutterfly.eps}
    \caption{Flattened Butterfly结构}
    \label{flattenedbutterfly}
\end{figure}

2009年SC会议上提出的HyperX\upcite{hyperx}
结构实际上是基于Flattened Butterfly结构的扩展结构，
是一个可以灵活配置的高阶互连网络。
HyperX同样是一个$k\textrm{-}ary$ $n\textrm{-}cube$结构，
但是每一维上的$k$值可以取不同值，
而且每个路由节点所连接的终端数以及每一维上的链路带宽都可以随意配比。
在网络规模、性能需求和能耗成本开销上，
这类可灵活配置的拓扑结构都更适合实际系统的需求。
Hypercube和Flattened Butterfly都是HyperX的特例。

%% FIXME 可能是因为第一章就没有把k-ary n-cube和k-ary n-fly 解释清楚，
%% 后面的拓扑结构感觉都没那么容易理解，以外行的眼光。

\subsection{Dragonfly}

Dragonfly\upcite{dragonfly}结构是一个有标志意义的高阶互连网络，
也是大规模低直经高性能互连网络的典型代表。
相比低阶互连网络，高阶互连网络拥有更多的全局链路，使用更多的长缆线。
为了解决高阶互连网络长缆线成本开销的问题，Dragonfly利用层次化的结构有效
减少了全局链路的数量并同时支持较大的网络规模和较低的网络直径。

Dragonfly具体构造是将$a$个高阶路由器通过全互连的方式相连成虚拟的更高阶超级节点，
每个路由节点引出$a-1$条本地链路连接同一个超级节点内的其他路由节点，
如图\ref{dragonfly}中虚线框所示。每个路由器引出$h$条全局链路
链接其他超级节点内的路由节点。
在全局网络中，虚拟的更高阶超级节点两两之间至少有一条链路相连，
如图\ref{dragonfly}中虚线框之间的连线所示。
通过在不同层次的网络中采用全互连结构，Dragonfly的网络直径只有3。
相比同样规模和同样节点度数的Flattened Butterfly结构，
Dragonfly结构可以节省近一半的全局链路。

\begin{figure}[htp]
  \centering
    \includegraphics[width=.56\textwidth,height=.35\textwidth]{Visio-dragonfly.eps}
    \caption{Dragonfly结构}
       \label{dragonfly}
\end{figure}

在2017年HiPINEB会议上提出的Dragonfly+\upcite{Dragonfly+}
拓扑结构是在Dragonfly结构的基础上进行扩展优化，
使用直径为2的树形结构替代Dragonfly结构超级节点内的全互连网络，
同时保持网络直径为3，
Dragonfly+使用图\ref{dragonfly+}所示的结构替代图\ref{dragonfly}中的超级节点。
使用相同端口数的路由芯片搭建网络，
Dragonfly+结构可以支持的最大网络规模接近Dragonfly结构的4倍。

\begin{figure}[htp]
  \centering
    \includegraphics[width=.48\textwidth]{Visio-dragonfly+.eps}
    \caption{Dragonfly+结构中超级节点模块}
    \label{dragonfly+}
\end{figure}

\subsection{Slim Fly}
Slim Fly\upcite{slimfly}是一个近似最优的高性能互连网络拓扑结构。
Slimf Fly的设计目标是，在直径为2的前提下，
使用尽可能少的路由器端口数构造更大规模的拓扑结构。
Slim Fly结构是继Dragonfly结构之后又一个标志性拓扑结构，
其利用代数图论的构造方法，
满足了低直径大规模的要求，
而且在二分带宽和成本能耗以及容错性上都展现了较优的性能。

Slim Fly采用了代数图论里的MMS图\upcite{MMS}。
其构造取决于一个基本参数$q$，$q$是一个素数的幂，可以表示为
$q=4w+\delta$，其中$\delta \in \{-1,0,1\}$。
Slim Fly图是一个高对称性的结构，由两个子图构成，
%% FIXME 每个子图多少子组，每个子组多少节点，用符号表示。
%% 检查以下我理解的对不对，每个子组是不是q个路由节点？
每个子图内包括$q$个子组，每个子组包含$q$个路由节点。
在Slim Fly中，每个路由器引出$(q-\delta)/2$条链路连接同一个子组内的其他路由节点，
$q$条链路分别连接另一个子图中$q$个子组的路由节点。
如图\ref{slimflyone}所示，
Slim Fly中的每个路由节点用一个三元组$(a,x,y)$标识，
其中$a\in \{0,1\}$标识子图的编号，
$x,y\in\mathds{F}_q$分别标识在所在子图中子组的编号和
所在子组中路由节点的编号。

令集合$X$和$X'$表示有限域$\mathds{F}_q$的两个生成集\upcite{MMS}\upcite{GRMMS}，
他们可以通过有限域$\mathds{F}_q$的生成元$\xi$
通过式\ref{equ:generator-sets0}和\ref{equ:generator-sets1}构造。
那么Slim Fly结构中的链路构造方式如下：
\begin{itemize}
\item 当且仅当$y-y' \in X$，路由节点$(0,x,y)$与路由节点$(0,x,y')$相连。
\item 当且仅当$y-y' \in X'$，路由节点$(1,x,y)$与路由节点$(1,x,y')$相连。
\item 当且仅当$y=x'x+y'$，路由节点$(0,x,y)$与$(1,x',y')$相连。
\end{itemize}

\begin{figure}
  \centering
    \includegraphics[width=.6\textwidth]{Visio-Slimfly_between.eps}
    \caption{Slim Fly结构}
    \label{slimflyone}
\end{figure}

\begin{equation}\label{equ:generator-sets0}
  X=
  \begin{cases}
    \{1,\xi^2,\ldots,\xi^{q-3}\}& q=4 \ell+1 \\
    \{1,\xi^2,\xi^4,\ldots, \xi^{2\ell-2},\xi^{2\ell-1},\xi^{2\ell+1},\ldots, \xi^{4\ell-3}\} & q=4 \ell-1 \\
    \{1,\xi^2,\ldots,\xi^{4l-2}\} & q=4 \ell
  \end{cases}
\end{equation}
\begin{equation}\label{equ:generator-sets1}
  X'=
  \begin{cases}
    \{\xi,\xi^3,\ldots,\xi^{q-2}\} & q=4 \ell+1 \\
    \{\xi,\xi^3,\xi^5,\ldots,\xi^{2\ell-1}, \xi^{2\ell},\ldots,\xi^{4\ell-4},\xi^{4\ell-2}\}\ \ \ \  & q=4 \ell-1 \\
    \{\xi,\xi^3,\ldots,\xi^{4l-1}\} & q=4 \ell
  \end{cases}
\end{equation}

%% FIXME 上面没说SF的全局网络是什么
在实际物理部署中，Slim Fly可以部署成全局网络是一个全互连网络。
分别位于相邻子图的两个子组封装成一个机柜，
那么任意两个机柜之间都有$2q$条链路，
%% FIXME 这句话在图中也体现不出来
如图\ref{slimfly}所示，图中每一个方框都是一个机柜并
两两之间用$2q$条链路相连。

\begin{figure}[htp]
  \centering
    \includegraphics[width=.3\textwidth,height=.5\textwidth]{Visio-Slimfly.eps}
    \caption{Slim Fly结构的全局网络}
    \label{slimfly}
\end{figure}

在2015的SC会议上，两种网络直径为2的间接拓扑结构
OFT（two-level Orthogonal Fat-Trees）和MLFM（Multi-Layer Full-Mesh）
被提出\upcite{costeffective2}，
分别如图\ref{oft}和\ref{mlmf} 所示。OFT和MLFM可以通过调整参数值灵活支持
不同规模。
在相同条件下，OFT相比Slim Fly和MLMF可以构造近似2倍规模的网络，
MLMF的可扩展性跟Slim Fly一样。
这三种拓扑结构的相同点就是平均每个终端都是消耗3个路由器端口和2条链路。
%% FIXME 这段话仅仅说OFT在规模上更好，但MLFM等于啥都没说。
%% 况且，OFT规模比SF大，那缺点呢？不都是tradeoff么。
%% 再况且，只说如图所是，还应该加一点对图的解释。

\begin{figure}[htp]
  \centering
    \includegraphics[width=.6\textwidth]{oft.eps}
    \caption{OFT结构\upcite{costeffective2}}
    \label{oft}
\end{figure}

\begin{figure}[htp]
  \centering
    \includegraphics[width=.6\textwidth]{mlmf.eps}
    \caption{MLMF结构\upcite{costeffective2}}
    \label{mlmf}
\end{figure}

\subsection{随机拓扑}

除了前面介绍的规则拓扑外，
随机拓扑也是高性能互连网络新型拓扑结构的一个重要类型。
最早是在数据中心网络中提出使用小世界网络\upcite{smallworld}构造系统。
通过在规则拓扑结构上添加随机链路构造出具有小世界网络特性的随机网络，
图\ref{sw2d}展示了一种在2D Torus结构上添加随机链路构小世界网络形成的拓扑结构。
在约束节点度情况下，具有小世界网络特性的网络
不仅可以拥有较短的网络直径，而且具备较高带宽和较短平均最短路径。
Singla等人提出将Jellyfish\upcite{Jellyfish}
运用在top-of-rack（ToR）交换机之间。
Jellyfish是一个绑定节点度的随机图拓扑结构，
不仅可以支持任意规模，而且相比同样配置的Fat tree，
可以支持更多的节点并提供至少一样的带宽。
Valadarsky等人指出当前最新的拓扑结构，如Slim Fly和Jellyfish，
都是expander图\upcite{xpander}。
但是，在性能上这些拓扑结构还不能达到近似最优，并在它们扩展上和部署上都存在困难。
因此，他们提出Xpander结构\upcite{xpander}，不仅提供近似最优的性能，
而且切实提高了部署可行性。
Xpander是一个灵活扩展的拓扑结构，
每个节点表示一个ToR交换机，每个节点有$d$个端口连接其他ToR交换机，
扩展则以包含$d+1$个节点的全互连图为单位进行。
通常情况下，Xpander结构都是通过翻倍的方式扩展，
但是Xpander也支持线性扩展来满足任意规模。
图\ref{xpander}给出了$d=2$的Xpander结构，
即，每个节点有2个端口连接其他节点，
以3个节点的全互连图为单位，如图\ref{xpander}的左边部分所示，
翻倍扩展成节点为6的Xpander结构，如图\ref{xpander}的中间部分所示。
翻倍后结构中的连线可以如图\ref{xpander}的右边部分所示。
%% FIXME 从这个图上看不出是怎么扩展的，也看不出d表示什么

\begin{figure}[htp]
\centering
\includegraphics[width=.5\textwidth]{sw2d.png}
\caption{小世界网络\upcite{smallworld}}
\label{sw2d}
\end{figure}
%% FIXME 这个图的线太细了

\begin{figure}[htp]
\centering
\includegraphics[width=.8\textwidth]{xpander.png}
\caption{Xpander结构\upcite{xpander}}
\label{xpander}
\end{figure}

Koibuchi等人\upcite{acaserandom}首先提出在高性能互连网络中采用随机拓扑结构
以满足系统延迟低、灵活扩展等需求。
具体构造方式类似于小世界网络，在圆环拓扑结构上添加随机链路，
可以支持任意规模的网络。
在2013年的HPCA会议上，
Koibuchi等人在之前提出的随机拓扑上进行了优化\upcite{layoutrandom}，
加入了物理布局的考虑，限制了缆线的长度。
之后在2015年的IPDPS会议上他们研究组提出Skywalk拓扑结构\upcite{skywalk}，
其进一步约束随机链路在实际物理布局的三维结构中的连接方式
来降低链路延迟对网络延迟的影响。
在2015年的HPCA会议上，
他们研究组提出在机柜间利用基于自由空间光（FSO）的随机链路来
降低网络延迟并优化任务分配\upcite{fsorandom}。
如图\ref{fso}所示，通过在机柜上部署FSO设备，
以便根据任务负载添加FSO通信链路以优化性能。

虽然随机拓扑可以提供较短的网络直径和平均最短路径，
并可以灵活支持任意规模，
但是，路由算法是限制随机拓扑应用于实际系统部署的主要原因之一。
由于随机拓扑结构只能通过路由表的方式进行路由，
随着网络规模的增长，路由表规模呈指数级增长，这是在实践中难以接受的。

\begin{figure}[htp]
\centering
\includegraphics[width=.7\textwidth]{fso.png}
\caption{添加FSO链路的高性能互连网络\upcite{fsorandom}}
\label{fso}
\end{figure}

\section{高性能互连网络路由算法}

拓扑结构和路由算法是紧密相关的，路由算法决定了拓扑结构的实际网络性能。
路由算法除了决定报文在拓扑结构的路径也同时影响网络
在实际通信下的拥塞情况以及网络的死锁避免策略。
虽然在高性能互连网络中，新型拓扑的连接方式多种多样，
但是，相同点都是网络规模大且直径低。
这个相同点造成了新型拓扑结构只有少量的冗余最短路径且部分关键链路使用频率高。
如Slim Fly\upcite{slimfly}结构中只有
极少量的节点对之间的最短路径多于一条，
Dragonfly\upcite{dragonfly}结构中超级节点之间的链路负载很重，容易造成网络的拥塞。
在实际通信中，为了满足不同的应用负载，
使用自适应路由算法是提升网络性能、解决网络中链路拥塞的主要方法之一。
然而，在新型拓扑结构中只能使用非最短路径代替最短路径，
这不仅给自适应路由算法的性能造成影响，
同时也给死锁避免策略带来成本开销和工艺设计等挑战。

Dragonfly结构是高性能互连网络的新型拓扑结构典型代表之一，
学术界针对其结构特点提出了很多路由算法。

最短路径路由（MIN）是Dragonfly结构上最简单和最基本的路由算法\upcite{dragonfly}。
使用最短路径路由最多只需3跳就能将报文从源路由节点传送到目的路由节点，
即：源路由节点所在的超级节点内的本地链路、
源超级节点和目的超级节点的全局链路和目的超级节点的本地链路。
因为Dragonfly的结构特点，本地链路和全局链路的VC可以复用，
因此MIN算法至少需要两条VC来避免死锁。

非最短路径路由又称Valiant路由算法（VAL）\upcite{dragonfly}，
是针对高负载流量提出的路由算法。
报文先选择一个中介节点作为第一个目的路由节点，
当通过MIN从源路由节点到达中介节点后再通过MIN从中介节点到达目的路由节点。
这样做的好处是，缓解高负载流量对全局链路的过度请求。
具体在实施时Valiant路由算法可划分为两种，
一种（VAL）是以中介节点所在的超级节点为第一目的地，
只要报文到达中介节点所在的超级节点就将目的地换成真正的目的路由节点。
第二种（VAL$_n$\upcite{overcomefarend}）则是按前面介绍的以中介节点为第一目的地。
第一种VAL最长需要经过5跳到达终点，途
经3条本地链路和2条全局链路。
VAL$_n$则最长需要经过6跳到达终点，途经3条本地链路和3条全局链路。
两种算法都至少需要3条VC来避免死锁。

在均衡随机通信模式下，VAL相比MIN，不仅跳步数翻倍，
吞吐率也会相应减半。而在密集高负载的最差通信模式下，
MIN则会造成全局链路的严重堵塞。
根据网络状态选择走VAL机制或是MIN机制是均衡全局自适应路由算法
（UGAL）的主要机制\upcite{dragonfly}。
网络状态则由路由端口缓冲区队列长度和报文的跳步数共同决定。
由于UGAL最长跳步数由VAL机制决定，
因此，UGAL同VAL一样至少需要3条VC来避免死锁。

上述四种Dragonfly结构路由算法存在一个共同的问题，那就是不能及时感知并反馈全局链路的拥塞状况。
因此，有研究提出间接自适应路由算法\upcite{indirect}来迅速对全局链路的拥塞作出反馈。
图\ref{dragonflyir}展示了四种不同的间接自适应路由算法，其中
橙色线表示控制信息传输路径，黑色线
表示报文路由路径，GC表示全局缆线。。
第一种间接自适应路由算法CRT（Credit Round Trip），
通过感知本地链路的信用反馈延迟来判断全局链路拥塞情况使得UGAL算法及时对拥塞做出
反馈，如路由器R0通过本地链路给路由器R1发送报文再通过全局链路给路由器R2发送报文，
路由器R1给路由器R0的信用反馈需等到路由器R2的信用反馈返回到R1才能发送。
CRT通过背压的方式获得全局链路的拥塞信号，
但是可能会造成本地链路拥塞。
第二种间接自适应路由算法PAR（Progressive Adaptive Routing），
如图\ref{dragonflyir}所示，在源超级节点根据当前
拥塞情况作出路由决策，选择MIN或者VAL。
这种方法在发现全局链路拥塞时不会将拥塞情况反馈给源路由器。
该算法会多走一跳本地链路，在使用VC隔离的方法来避免死锁时，需要多一条VC。
PAR可以扩展到在经过的每一个超级节点内部都根据当前网络状态选择MIN或者VAL。
第三种间接路由算法PB（Piggyback），
如图\ref{dragonflyir}所示，
通过给相邻节点广播全局链路的拥塞状态作出路由选择。
具体实现则需要在每个报文上都增加一个记录链路状态的向量位。
每个路由器都需要维护同一个超级节点内全局链路的状态信息。
该算法缺点是路由器需要维护全局链路拥塞信息的更新。
第四种间接路由算法RES（Reservation），
如图\ref{dragonflyir}所示，该方法是报文提前预约全局链路的资源，
如果预约成功则执行MIN路由，不成功则执行VAL路由。
该方法可能会造成预约信息泛滥，并且预约信息可能不及时。


%% FIXME 这个图的问题在于太小了。四个算法应该分成四个子图，最多并排两个，
%% 而且，这个图本身缺乏必要的解释。如，黑色线，橙色线分别什么意义，GC是什么的缩写……
\begin{figure}[htp]
  \centering
    \includegraphics[width=.95\textwidth]{Visio-dragonfly_indirect.eps}
    \caption{Dragonfly结构间接自适应路由算法\upcite{indirect}}
       \label{dragonflyir}
\end{figure}

针对一些特定的通信负载，如最差通信负载，
Dragonfly结构中确定的两个超级节点频繁通信，
不仅会造成全局链路拥塞，还会同时造成本地链路拥塞。
如图\ref{dragonflytr}所示，
在采用了VAL的路由选择后仍然会因为同一个超级节点的
两个路由器所连接的超级节点之间频繁转发报文导致两个路由器之间的本地链路拥塞。
%% FIXME 结合这个图，上面这句话说的似乎不太明确，我没看懂。
因此，研究者提出On-the-Fly 自适应路由算法（OFAR）\upcite{On-the-Fly}
来解决本地链路和全局链路的拥塞问题。
OFAR通过允许在超级节点内部进行本地链路的绕路，
有效避免了因为全局链路拥塞造成的本地链路的拥塞。
OFAR最长路径长度要达到8跳，如果采用VC隔离的方式避免死锁则至少需要6条VC。
OFAR最初采用的是基于气泡流量控制的哈密尔顿环作为逃逸子网，
OFAR-CM\upcite{OFAR-CM}则在OFAR 的基础上提出拥塞管理机制ECM和BCM，
这两种拥塞控制机制分别关注的是逃逸子网的拥塞情况和正常网络的拥塞情况，
该研究还提出采用树型逃逸子网和up-down路由算法。

\begin{figure}[htp]
  \centering
    \includegraphics[width=.45\textwidth]{Visio-dragonfly_traffic.eps}
    \caption{Dragonfly结构中全局链路导致本地链路拥塞}
       \label{dragonflytr}
\end{figure}

路由算法中的死锁避免，有多种方法，大致可以分为三类：
一是设计无环路由，二是通过虚拟通道（VC）切换的方式避免死锁，
三是通过逃逸子网的方式避免死锁。
这其中，无环路由是最经济的方法，但是会因限制部分路径不能通行，降低网络吞吐率。
VC 切换的方法的优势是可以充分利用网络中的链路，
但是VC数量的增加给工艺和成本开销带来挑战。
逃逸子网使用一套独立的VC网络或者
物理网络执行一个没有环路的路由算法来避免整个网络的死锁，
相比前两种方法，逃逸子网可以算是一个折中的办法，
但是逃逸子网的使用频率影响网络性能。
RLM 和OLM算法\upcite{Rlmolm}的提出有效降低了OFAR对VC的需求。
RLM在超级节点内部采用转弯模型的方式避免死锁，即超级节点内部采用无环路由，
通过减少路径多样性降低VC数量。
OLM则是采用限制VC使用顺序的方式避免死锁，
利用VC降序作为逃逸路径，
在保证超级节点内的路径多样性的同时不额外增加VC数量。

除了考虑不同的通信负载和拓扑结构的特征，
也要考虑实际物理布局中缆线长短对路由算法决策的影响。
在\upcite{overcomefarend}中指出目前大多数
已有的工作都没有考虑远端延迟的影响，即下几跳后的网络拥塞和因路由器之间
较长链路延迟高引起的拥塞，实际上这些拥塞都只是暂时性的拥塞，
不会导致网络真正拥塞。
比如，较长的链路延迟会使得一些报文或者信用不能及时到达终点从而造成拥塞的假象。
因此，作者通过历史窗口的方法来避免这种假象影响自适应路由的决策
\upcite{overcomefarend}。

另外，是否能够合理分配缓冲区资源也是路由算法的性能的影响因素。
Gorgues等人\upcite{Achieving}提出在$k\textrm{-}ary$ $n\textrm{-}cube$结构的片上网络上，
通过报文标记的方法给报文均衡分配网络中的缓冲区资源并利用更少的资源来避免死锁。
具体设计是每个输入端口有2条VC，
每条VC被分配一个报文长度的缓冲区大小。
完全自适应路由算法通过通过一条逃逸路径来避免死锁。
每次路由决策都可能改变报文的标记，
如果报文的决策是按维序路由算法路由的话就被标记为安全报文。
否则，则被标记为不安全报文。
每个端口的两条VC中至少有一条VC里全是安全报文或者为空。
我们考虑将这种方法运用在片间网络上，不仅可以避免工艺上的挑战又能充分利用网络资源。

Head-of-Line Blocking（HoLB）问题也是影响路由算法性能的重要因素。
HoLB问题是指位于队列头的报文因为下一级拥塞不能前进阻挡了队列中其他报文前进。
相比确定性路由算法，即在源节点已经确定好报文传输路径，
自适应路由算法因为路由的灵活性会造成报文传输路径不唯一，
更容易造成HoLB问题\upcite{holbara}。
有研究组针对不同拓扑结构路由算法的HoLB问题提出了解决办法。
如在\upcite{holbara}中，针对直接网络的自适应路由算法，
利用有限的VC，将不同目的节点的报文分配到不同的VC中传输。
在\upcite{bbq}\upcite{DBBM}\upcite{iodet}中，
都使用类似的方法解决HoLB问题。
另外，提出上述方法的研究组也针对Dragonfly结构、Slim Fly结构
等典型新型高性能互连网络拓扑结构的路由算法提出了HoLB问题的解决方案
\upcite{holbdf}\upcite{holbsf}。
在FlexVC\upcite{flexvc}中则是提出一个缓冲区管理策略来降低网络HoLB问题，
具体方法就是在保证无死锁的前提下，
尽可能的增大VC可选择的范围。
如针对Slim Fly结构，如果采用最短路径路由算法，
网络中有3条VC的时候，报文就可以选择Opportunistic路径进行路由来降低HoLB问题。

\section{高性能互连网络拥塞控制机制}
拥塞控制机制与路由算法是影响高性能互连网络网络性能的重要因素。
自适应路由算法旨在解决网络中的链路拥塞问题，
而拥塞控制机制则是解决终端节点的超额订购。
当两者搭配使用才能更好的提升网络性能\upcite{cbcm}。
%% FIXME 把这句话从后面移到此处，是否使得后面CBCM的表述不清楚？

由于高性能互连网络具备无损的特性，即不会因为网络拥塞而丢包，
传统的拥塞控制机制，如TCP协议，就不适用于高性能互连网络。
高性能互连网络中经典的拥塞控制机制，
如Explicit Congestion Notification（ECN）拥塞控制机制，
是一种被动的拥塞控制机制，根据缓冲队列长度，
给报文打标签，到达目的节点后将拥塞信息通过ACK报文告诉源节点。
这种策略最大的缺点就是不能及时对拥塞作出反馈，响应速度慢。
在2012年的SC会议上，Jiang等人提出
Speculative Reservation Protocol（SRP）\upcite{srp}拥塞控制机制。
SRP是一种主动拥塞控制机制，
通过light-weight的终端预约机制以及投机报文传输机制有效缓解热点通信模式下的拥塞，
获得比ECN机制更高的吞吐率。
之后，该研究组在2013年SC会议上提出
Channel Reservation Protocol（CRP）\upcite{crp}策略，
专门解决大规模无损网络通信中关键链路拥塞的问题。
因为考虑到成本和技术的限制，集群之间的链路都是供小于求，
如图\ref{crp}所示，如果热点H不能正常吸收负载则会造成
数据流Z拥塞在点A，进而产生拥塞树，
不仅影响集群0的数据流Y还影响集群1内要到达点H的数据流。
CRP通过预约关键链路的方法来解决瓶颈链路拥塞的问题。
在2015年的SC会议上，
该研究组针对ECN和SRP对small message终端拥塞反应速度慢和易造成
拥塞树等不足，
提出Small-Message SRP（SMSRP）和
Last-Hop Reservation Protocol（LHRP）两种策略\upcite{smsrp}。
相较于SRP策略，
SMSRP策略会在发送预约报文之前发送一些投机报文以免造成带宽浪费
以及因为预约产生的动荡。
LHRP相较于SRP和SMSRP策略的不同之处是在最后一跳交换机处根据终端的缓冲队列长度对
投机报文传输失败作出反馈。

\begin{figure}[htp]
  \centering
    \includegraphics[width=.65\textwidth]{crp.png}
    \caption{集群间的拥塞树\upcite{crp}}
       \label{crp}
\end{figure}

除了上述基于预约的拥塞控制机制，Kim等人在2016年的MICRO会议上
提出一种新的拥塞管理策略Contention-based Congestion Management（CBCM）
\upcite{cbcm}。该研究指出，当网络中只采用自适应路由算法来提升网络性能的时候，
往往会造成拥塞扩散性能降低的情况。
CBCM的原理如图\ref{cbcm}所示，CBCM专门使用一条额外的VC分离终端拥塞的影响，
一旦发现终端拥塞，即终端接收到被标记的报文超过阈值，
则节流相应的源节点，且节流的报文在此额外的VC中采用最短路由算法，
从而避免因为自适应路由算法扩散拥塞。

\begin{figure}[htp]
  \centering
    \includegraphics[width=.65\textwidth]{cbcm.png}
    \caption{Contention-based Congestion Management机制\upcite{cbcm}}
       \label{cbcm}
\end{figure}
%\section{模拟环境和性能测试平台}

\section{本章小结}
本章主要阐述了高性能互连网络新型拓扑结构的理论基础和相关研究。
主要综述了目前已提出的新型型高性能互连网络拓扑结构和典型路由算法、拥塞控制机制等内容。
%% 本文基于大规模低直径的特点开展高性能互连网络拓扑结构设计和路由算法的研究。
